{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ_5U-JxQQhQ"
      },
      "source": [
        "# Colab MSA-Search with Many Proteins\n",
        "\n",
        "Runs MSA-Search NIM and saves result as `A3M` format file.\n",
        "\n",
        "MSA-Search NIM: https://build.nvidia.com/colabfold/msa-search\n",
        "\n",
        "27Aug2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxeMs4KwQQhR"
      },
      "source": [
        "## 1.1 Set Up the Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pandas tqdm httpx \"fastapi[standard]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Kwwr0x8QQhR"
      },
      "outputs": [],
      "source": [
        "import os, requests, re\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import userdata, files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Input File and Output Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_file_path = \"UniprotID_and_FastaSequences_100_Examples.csv\"\n",
        "\n",
        "output_dir = \"/content/output\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvI9Bw7rQQhR"
      },
      "source": [
        "## 1.2 Set Up `output` Directory and `API_KEY`\n",
        "\n",
        "**NOTE:** Be sure to follow the steps in the README to embed your NVIDIA `API_KEY` into your Google Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylQVJvcvQQhR"
      },
      "outputs": [],
      "source": [
        "API_KEY = userdata.get('API_KEY')\n",
        "\n",
        "# Ensure output directory exists, create if not present\n",
        "if os.path.exists(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MSA_DATABASES = ['Uniref30_2302', 'colabfold_envdb_202108', 'PDB70_220313']\n",
        "\n",
        "def msa_search(sequence, API_KEY, databases=MSA_DATABASES):\n",
        "    msa_search_url = \"https://health.api.nvidia.com/v1/biology/colabfold/msa-search/predict\"\n",
        "    payload = {\n",
        "        \"sequence\": sequence,\n",
        "        \"databases\": databases,\n",
        "        \"e_value\": 0.0001,\n",
        "        \"iterations\": 1,\n",
        "        \"max_msa_sequences\": 10000,\n",
        "        \"run_structural_template_search\": False,\n",
        "        \"output_alignment_formats\": [\"a3m\"],\n",
        "    }\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"content-type\": \"application/json\",\n",
        "        \"NVCF-POLL-SECONDS\": \"300\",\n",
        "    }\n",
        "    # Call MSA-Search NIM\n",
        "    response = requests.post(msa_search_url, json=payload, headers=headers)\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def parse_sequences(input_string, n, sequence):\n",
        "    \"\"\"\n",
        "    Parse the output of alignments from the MSA-Search NIM to be used downstream\n",
        "    \n",
        "    Args:\n",
        "        input_string (str): The output file of alignments in a string format\n",
        "        n (int): The amount of alignments to return from the output when parsing\n",
        "        sequence (str): The query sequence for alignment\n",
        "    \n",
        "    Returns:\n",
        "        list: A list of alignment identifiers and sequences, starting with the query,\n",
        "              where the amount of sequences is given by n\n",
        "    \"\"\"\n",
        "    # Output is parsed to have a line for the sequence id and sequence itself so `n` returns correlates to n*2 lines\n",
        "    n = n * 2\n",
        "    # First, handle the `Query` block separately\n",
        "    lines = input_string.strip().split('\\n')\n",
        "    # Now process the rest of the lines\n",
        "    remaining_string = \"\\n\".join(lines[:])\n",
        "    # Regex to find blocks starting with `>` and then followed by a sequence.\n",
        "    pattern = re.compile(r'\\n>(.*?)\\n(.*?)(?=\\n>|\\Z)', re.DOTALL)\n",
        "    matches = pattern.finditer(remaining_string)\n",
        "    output_list_to_order = []\n",
        "    for match in matches:\n",
        "        # The name is the first capturing group, split by tab and take the first part\n",
        "        name_full = match.group(1).split('\\t')[0]\n",
        "        SW_score = match.group(1).split('\\t')[1]\n",
        "        # The sequence is the second capturing group\n",
        "        sequence_raw = match.group(2).strip()\n",
        "        sequence = ''.join(char for char in sequence_raw if char.isupper() or not char.isalpha())\n",
        "        # Store the aligned sequence in the list of outputs by name, sequence, Smith-Waterman score\n",
        "        output_list_to_order.append((f'>{name_full}', sequence, int(SW_score)))\n",
        "    output_lines = output_list_to_order[:n]\n",
        "    return output_lines\n",
        "\n",
        "\n",
        "def write_alignments_to_a3m(alignments_data, uniprot_id, output_dir):\n",
        "    \"\"\"\n",
        "    Write alignment data to a3M format file.\n",
        "    \n",
        "    Args:\n",
        "        alignments_data: Either a list of alternating headers/sequences or a string containing alignments\n",
        "        uniprot_id (str): Uniprot ID of the protein\n",
        "        output_dir (str): Directory for the output a3M file\n",
        "    \n",
        "    Returns:\n",
        "        str: Path to the created a3M file\n",
        "    \"\"\"\n",
        "    output_path = Path(output_dir) / f\"{uniprot_id}_msa_alignments.a3m\"\n",
        "    # Handle both list and string input formats\n",
        "    if isinstance(alignments_data, list):\n",
        "        alignments_string = '\\n'.join(alignments_data)\n",
        "    elif isinstance(alignments_data, str):\n",
        "        alignments_string = alignments_data\n",
        "    else:\n",
        "        raise ValueError(\"alignments_data must be either a list or string\")\n",
        "    # Count sequences for reporting\n",
        "    sequence_count = alignments_string.count('>')\n",
        "    print(f\"Writing {sequence_count} sequences to a3M format: {output_path}\")\n",
        "    try:\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            # Write the alignments\n",
        "            f.write(alignments_string)\n",
        "            # Ensure file ends with newline\n",
        "            if not alignments_string.endswith('\\n'):\n",
        "                f.write('\\n')\n",
        "        # Verify the file was created successfully\n",
        "        if output_path.exists():\n",
        "            file_size = output_path.stat().st_size\n",
        "            print(f\"Successfully created a3M file:\")\n",
        "            print(f\"File: {output_path}\")\n",
        "            print(f\"Size: {file_size:,} bytes\")\n",
        "            print(f\"Sequences: {sequence_count}\")\n",
        "            return str(output_path)\n",
        "            files.download(output_path)\n",
        "        else:\n",
        "            raise IOError(f\"Failed to create file {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing a3M file: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "\n",
        "def process_msa_alignments(msa_response_dict, sequence, uniprot_id, output_dir, databases=MSA_DATABASES, max_sequences_per_db=10000):\n",
        "    \"\"\"\n",
        "    Process MSA alignments from multiple databases and merge them into A3M format.\n",
        "    \n",
        "    Args:\n",
        "        msa_response_dict (dict): MSA response data containing alignments\n",
        "        sequence (str): Query sequence for alignment\n",
        "        uniprot_id (str): Uniprot ID of the protein\n",
        "        output_dir (str): Output directory for the A3M file\n",
        "        databases (list): List of database names to process\n",
        "        max_sequences_per_db (int): Maximum number of sequences to parse per database\n",
        "    \n",
        "    Returns:\n",
        "        str: Path to the created A3M file\n",
        "    \"\"\"\n",
        "    all_parsed_dataset_output = []\n",
        "    for database in databases:\n",
        "        print(f\"Parsing results from database: {database}\")\n",
        "        # Pull string of alignments stored in json output for specific dataset\n",
        "        a3m_dict_msa_search = msa_response_dict['alignments'][database]['a3m']['alignment']\n",
        "        a3m_dict_msa_search_parsed = parse_sequences(a3m_dict_msa_search, max_sequences_per_db, sequence)\n",
        "        num_sequences_aligned = (len(a3m_dict_msa_search_parsed))\n",
        "        print(f\"Number of sequences aligned: {num_sequences_aligned}\")\n",
        "        all_parsed_dataset_output.extend(a3m_dict_msa_search_parsed)\n",
        "    # Sort all the alignments based off of the alignment score\n",
        "    all_parsed_dataset_output.sort(key=lambda x: x[2], reverse=True)\n",
        "    # Now that the alignments across all datasets are sorted, reformat each entry to name and sequence\n",
        "    sorted_parsed_output_formatted = []\n",
        "    for align_tuple in all_parsed_dataset_output:\n",
        "        sorted_parsed_output_formatted.append(align_tuple[0])\n",
        "        sorted_parsed_output_formatted.append(align_tuple[1])\n",
        "    merged_alignments_protein = [f\">query_sequence\\n{sequence}\"]\n",
        "    merged_alignments_protein.extend(sorted_parsed_output_formatted)\n",
        "    print(f\"Total merged alignments: {len(merged_alignments_protein)}\")\n",
        "    # Write merged_alignments_protein to a3M format\n",
        "    a3m_file_path = write_alignments_to_a3m(\n",
        "        merged_alignments_protein, \n",
        "        uniprot_id,\n",
        "        output_dir\n",
        "    )\n",
        "    return a3m_file_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Load File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(csv_file_path, low_memory=False)\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoj321rTQQhR"
      },
      "source": [
        "## 1.4 Parse Protein Names and Sequences to only unique pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKRtkuWYQQhS"
      },
      "outputs": [],
      "source": [
        "seq_uniprot = df['uniprot_id'].tolist()\n",
        "sequences = df['fasta_uniprot_seq'].tolist()\n",
        "sequences = tuple(zip(seq_uniprot, sequences))\n",
        "sequences = sorted(list(set(sequences)))\n",
        "print(f\"Number of unique sequences: {len(sequences)} from parent dataset of {df.shape[0]} sequences\")\n",
        "sequences[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5 Loop Through Protein Names and Sequences with MSA-Search NIM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for seq_id, seq in tqdm(sequences[:1]):\n",
        "    msa_response_dict = msa_search(seq, API_KEY)\n",
        "    process_msa_alignments(msa_response_dict, seq, seq_id, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
