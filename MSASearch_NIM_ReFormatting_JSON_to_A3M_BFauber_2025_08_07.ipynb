{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2914136",
   "metadata": {},
   "source": [
    "## MSA-Search NIM Output Reformatting JSON into A3M Format\n",
    "\n",
    "Reformatting of JSON output from https://build.nvidia.com/colabfold/msa-search\n",
    "\n",
    "07Aug2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8daf8de",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1.1 Set Up Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b81a382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f8e4c",
   "metadata": {},
   "source": [
    "## 1.2 Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46cde631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_safely(filename, default_value=None):\n",
    "    \"\"\"\n",
    "    Load JSON file with robust error handling for common issues\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to JSON file\n",
    "        default_value: Default value to return if loading fails\n",
    "    \n",
    "    Returns:\n",
    "        dict: Loaded JSON data or default value\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"Successfully loaded {filename}\")\n",
    "        return data\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSONDecodeError in {filename}: {e}\")\n",
    "        print(f\"Error at line {e.lineno}, column {e.colno}\")\n",
    "        \n",
    "        # Try to show context around the error\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            lines = content.split('\\n')\n",
    "            if e.lineno <= len(lines):\n",
    "                start_line = max(0, e.lineno - 2)\n",
    "                end_line = min(len(lines), e.lineno + 1)\n",
    "                print(f\"Context around error:\")\n",
    "                for i in range(start_line, end_line):\n",
    "                    marker = \">>> \" if i == e.lineno - 1 else \"    \"\n",
    "                    print(f\"{marker}Line {i+1}: {lines[i][:80]}...\")\n",
    "        except Exception:\n",
    "            pass\n",
    "            \n",
    "        if default_value is not None:\n",
    "            print(f\"Using default value\")\n",
    "            return default_value\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {filename}\")\n",
    "        if default_value is not None:\n",
    "            print(f\"Using default value\")\n",
    "            return default_value\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error loading {filename}: {e}\")\n",
    "        if default_value is not None:\n",
    "            print(f\"Using default value\")\n",
    "            return default_value\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "\n",
    "def load_msa_data(msa_file_path):\n",
    "    \"\"\"\n",
    "    Load MSA (Multiple Sequence Alignment) data with robust error handling\n",
    "    \n",
    "    Args:\n",
    "        msa_file_path (str): Path to MSA JSON file\n",
    "    \n",
    "    Returns:\n",
    "        dict: MSA data or error information\n",
    "    \"\"\"\n",
    "    msa_file_path = Path(msa_file_path)\n",
    "    \n",
    "    if not msa_file_path.exists():\n",
    "        print(f\"MSA file not found: {msa_file_path}\")\n",
    "        return {\"alignments\": {}, \"error\": \"file_not_found\"}\n",
    "    \n",
    "    print(f\"Loading MSA data from: {msa_file_path}\")\n",
    "    \n",
    "    # Check file size\n",
    "    file_size = msa_file_path.stat().st_size\n",
    "    print(f\"File size: {file_size:,} bytes\")\n",
    "    \n",
    "    if file_size == 0:\n",
    "        print(f\"MSA file is empty\")\n",
    "        return {\"alignments\": {}, \"error\": \"empty_file\"}\n",
    "    \n",
    "    # Try to load the JSON\n",
    "    try:\n",
    "        msa_data = load_json_safely(str(msa_file_path), default_value={\n",
    "            \"alignments\": {},\n",
    "            \"error\": \"json_decode_error\",\n",
    "            \"templates\": {},\n",
    "            \"metrics\": {\"search_type\": \"unknown\"}\n",
    "        })\n",
    "        \n",
    "        # Validate the structure\n",
    "        if \"alignments\" in msa_data:\n",
    "            alignment_count = len(msa_data.get(\"alignments\", {}))\n",
    "            print(f\"Found {alignment_count} alignment(s)\")\n",
    "        else:\n",
    "            print(f\"No 'alignments' key found in data\")\n",
    "            \n",
    "        return msa_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load MSA data: {e}\")\n",
    "        return {\"alignments\": {}, \"error\": str(e)}\n",
    "\n",
    "\n",
    "def parse_sequences(input_string, n, sequence):\n",
    "    \"\"\"\n",
    "    Parse the output of alignments from the MSA-Search NIM to be used downstream\n",
    "    \n",
    "    Args:\n",
    "        input_string (str): The output file of alignments in a string format\n",
    "        n (int): The amount of alignments to return from the output when parsing\n",
    "        sequence (str): The query sequence for alignment\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of alignment identifiers and sequences, starting with the query,\n",
    "              where the amount of sequences is given by n\n",
    "    \"\"\"\n",
    "    # Output is parsed to have a line for the sequence id and sequence itself so `n` returns correlates to n*2 lines\n",
    "    n = n * 2\n",
    "\n",
    "    # First, handle the `Query` block separately\n",
    "    lines = input_string.strip().split('\\n')\n",
    "\n",
    "    # Now process the rest of the lines\n",
    "    remaining_string = \"\\n\".join(lines[:])\n",
    "\n",
    "    # Regex to find blocks starting with `>` and then followed by a sequence.\n",
    "    pattern = re.compile(r'\\n>(.*?)\\n(.*?)(?=\\n>|\\Z)', re.DOTALL)\n",
    "\n",
    "    matches = pattern.finditer(remaining_string)\n",
    "\n",
    "    output_list = []\n",
    "    output_list_to_order = []\n",
    "\n",
    "    for num_match, match in enumerate(matches):\n",
    "        # The name is the first capturing group, split by tab and take the first part\n",
    "        name_full = match.group(1).split('\\t')[0]\n",
    "        SW_score = match.group(1).split('\\t')[1]\n",
    "\n",
    "        # The sequence is the second capturing group\n",
    "        sequence_raw = match.group(2).strip()\n",
    "        sequence = ''.join(char for char in sequence_raw if char.isupper() or not char.isalpha())\n",
    "\n",
    "        # Store the aligned sequence in the list of outputs by name, sequence, Smith-Waterman score\n",
    "        output_list_to_order.append((f'>{name_full}', sequence, int(SW_score)))\n",
    "\n",
    "    output_lines = output_list_to_order[:n]\n",
    "\n",
    "    return output_lines\n",
    "\n",
    "\n",
    "def write_alignments_to_a3m(alignments_data, output_file_path, description=\"MSA alignments\"):\n",
    "    \"\"\"\n",
    "    Write alignment data to a3M format file.\n",
    "    \n",
    "    Args:\n",
    "        alignments_data: Either a list of alternating headers/sequences or a string containing alignments\n",
    "        output_file_path (str): Path for the output a3M file\n",
    "        description (str): Description for the file\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the created a3M file\n",
    "    \"\"\"\n",
    "    output_path = Path(output_file_path)\n",
    "    \n",
    "    # Handle both list and string input formats\n",
    "    if isinstance(alignments_data, list):\n",
    "        alignments_string = '\\n'.join(alignments_data)\n",
    "    elif isinstance(alignments_data, str):\n",
    "        alignments_string = alignments_data\n",
    "    else:\n",
    "        raise ValueError(\"alignments_data must be either a list or string\")\n",
    "    \n",
    "    # Count sequences for reporting\n",
    "    sequence_count = alignments_string.count('>')\n",
    "    \n",
    "    print(f\"Writing {sequence_count} sequences to a3M format: {output_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            # Write the alignments\n",
    "            f.write(alignments_string)\n",
    "            \n",
    "            # Ensure file ends with newline\n",
    "            if not alignments_string.endswith('\\n'):\n",
    "                f.write('\\n')\n",
    "        \n",
    "        # Verify the file was created successfully\n",
    "        if output_path.exists():\n",
    "            file_size = output_path.stat().st_size\n",
    "            print(f\"Successfully created a3M file:\")\n",
    "            print(f\"File: {output_path}\")\n",
    "            print(f\"Size: {file_size:,} bytes\")\n",
    "            print(f\"Sequences: {sequence_count}\")\n",
    "            \n",
    "            return str(output_path)\n",
    "        else:\n",
    "            raise IOError(f\"Failed to create file {output_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error writing a3M file: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def write_filtered_a3m(alignments_data, output_file_path, max_sequences=None, min_length=None, description=\"Filtered MSA alignments\"):\n",
    "    \"\"\"\n",
    "    Write alignment data to a3M format with optional filtering.\n",
    "    \n",
    "    Args:\n",
    "        alignments_data: String containing alignments in FASTA-like format\n",
    "        output_file_path (str): Path for the output a3M file\n",
    "        max_sequences (int, optional): Maximum number of sequences to include\n",
    "        min_length (int, optional): Minimum sequence length (excluding gaps)\n",
    "        description (str): Description for the file\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the created a3M file\n",
    "    \"\"\"\n",
    "    output_path = Path(output_file_path)\n",
    "    \n",
    "    # Parse sequences from the input data\n",
    "    if isinstance(alignments_data, str):\n",
    "        lines = alignments_data.strip().split('\\n')\n",
    "    else:\n",
    "        lines = '\\n'.join(alignments_data).strip().split('\\n')\n",
    "    \n",
    "    sequences = []\n",
    "    current_header = None\n",
    "    current_sequence = \"\"\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('>'):\n",
    "            # Save previous sequence if it exists\n",
    "            if current_header is not None:\n",
    "                sequences.append((current_header, current_sequence))\n",
    "            current_header = line\n",
    "            current_sequence = \"\"\n",
    "        else:\n",
    "            current_sequence += line\n",
    "    \n",
    "    # Don't forget the last sequence\n",
    "    if current_header is not None:\n",
    "        sequences.append((current_header, current_sequence))\n",
    "    \n",
    "    print(f\"Parsed {len(sequences)} sequences from input data\")\n",
    "    \n",
    "    # Apply filters\n",
    "    filtered_sequences = []\n",
    "    \n",
    "    for header, sequence in sequences:\n",
    "        # Apply minimum length filter (count non-gap characters)\n",
    "        if min_length is not None:\n",
    "            non_gap_length = len(sequence.replace('-', '').replace('.', ''))\n",
    "            if non_gap_length < min_length:\n",
    "                continue\n",
    "        \n",
    "        filtered_sequences.append((header, sequence))\n",
    "        \n",
    "        # Apply maximum sequences limit\n",
    "        if max_sequences is not None and len(filtered_sequences) >= max_sequences:\n",
    "            break\n",
    "    \n",
    "    print(f\"After filtering: {len(filtered_sequences)} sequences\")\n",
    "    if max_sequences:\n",
    "        print(f\"Max sequences limit: {max_sequences}\")\n",
    "    if min_length:\n",
    "        print(f\"Min length filter: {min_length}\")\n",
    "    \n",
    "    # Write to a3M format\n",
    "    try:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            # Write sequences\n",
    "            for header, sequence in filtered_sequences:\n",
    "                f.write(f\"{header}\\n{sequence}\\n\")\n",
    "        \n",
    "        # Report success\n",
    "        file_size = output_path.stat().st_size\n",
    "        print(f\"Successfully created filtered a3M file:\")\n",
    "        print(f\"File: {output_path}\")\n",
    "        print(f\"Size: {file_size:,} bytes\")\n",
    "        print(f\"Sequences: {len(filtered_sequences)}\")\n",
    "        \n",
    "        return str(output_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error writing filtered a3M file: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def analyze_a3m_file(file_path):\n",
    "    \"\"\"\n",
    "    Analyze an a3M file and provide statistics.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the a3M file\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Analyzing a3M file: {file_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Count statistics\n",
    "        total_lines = len(lines)\n",
    "        comment_lines = sum(1 for line in lines if line.startswith('#'))\n",
    "        sequence_headers = sum(1 for line in lines if line.startswith('>'))\n",
    "        sequence_lines = total_lines - comment_lines - sequence_headers\n",
    "        \n",
    "        # Calculate sequence lengths\n",
    "        sequence_lengths = []\n",
    "        current_sequence = \"\"\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            elif line.startswith('>'):\n",
    "                if current_sequence:\n",
    "                    sequence_lengths.append(len(current_sequence))\n",
    "                current_sequence = \"\"\n",
    "            else:\n",
    "                current_sequence += line\n",
    "        \n",
    "        # Don't forget the last sequence\n",
    "        if current_sequence:\n",
    "            sequence_lengths.append(len(current_sequence))\n",
    "        \n",
    "        # File statistics\n",
    "        file_size = file_path.stat().st_size\n",
    "        \n",
    "        print(f\"File Statistics:\")\n",
    "        print(f\"File size: {file_size:,} bytes\")\n",
    "        print(f\"Total lines: {total_lines}\")\n",
    "        print(f\"Comment lines: {comment_lines}\")\n",
    "        print(f\"Sequence headers: {sequence_headers}\")\n",
    "        print(f\"Sequence lines: {sequence_lines}\")\n",
    "        \n",
    "        if sequence_lengths:\n",
    "            avg_length = sum(sequence_lengths) / len(sequence_lengths)\n",
    "            min_length = min(sequence_lengths)\n",
    "            max_length = max(sequence_lengths)\n",
    "            \n",
    "            print(f\"Sequence Statistics:\")\n",
    "            print(f\"Number of sequences: {len(sequence_lengths)}\")\n",
    "            print(f\"Average length: {avg_length:.1f}\")\n",
    "            print(f\"Length range: {min_length} - {max_length}\")\n",
    "            \n",
    "            # Show first sequence as example\n",
    "            with open(file_path, 'r') as f:\n",
    "                content = f.read()\n",
    "                \n",
    "            # Find first sequence\n",
    "            lines = content.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                if line.startswith('>') and not line.startswith('#'):\n",
    "                    header = line\n",
    "                    sequence = \"\"\n",
    "                    j = i + 1\n",
    "                    while j < len(lines) and not lines[j].startswith('>'):\n",
    "                        if not lines[j].startswith('#'):\n",
    "                            sequence += lines[j].strip()\n",
    "                        j += 1\n",
    "                    \n",
    "                    print(f\"First sequence example:\")\n",
    "                    print(f\"Header: {header}\")\n",
    "                    print(f\"Length: {len(sequence)}\")\n",
    "                    print(f\"Preview: {sequence[:80]}{'...' if len(sequence) > 80 else ''}\")\n",
    "                    break\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing file: {e}\")\n",
    "\n",
    "\n",
    "def process_msa_alignments(msa_response_dict, databases, sequence, max_sequences_per_db=10000, output_file=\"merged_alignments_protein.a3m\"):\n",
    "    \"\"\"\n",
    "    Process MSA alignments from multiple databases and merge them into A3M format.\n",
    "    \n",
    "    Args:\n",
    "        msa_response_dict (dict): MSA response data containing alignments\n",
    "        databases (list): List of database names to process\n",
    "        sequence (str): Query sequence for alignment\n",
    "        max_sequences_per_db (int): Maximum number of sequences to parse per database\n",
    "        output_file (str): Output A3M file path\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (merged_alignments_protein, a3m_file_path)\n",
    "            - merged_alignments_protein: List of merged alignments\n",
    "            - a3m_file_path: Path to the created A3M file\n",
    "    \"\"\"\n",
    "    all_parsed_dataset_output = []\n",
    "    \n",
    "    for num_done, database in enumerate(databases):\n",
    "        print(f\"Parsing results from database: {database}\")\n",
    "\n",
    "        # Pull string of alignments stored in json output for specific dataset\n",
    "        a3m_dict_msa_search = msa_response_dict['alignments'][database]['a3m']['alignment']\n",
    "\n",
    "        a3m_dict_msa_search_parsed = parse_sequences(a3m_dict_msa_search, max_sequences_per_db, sequence)\n",
    "\n",
    "        num_sequences_aligned = (len(a3m_dict_msa_search_parsed))\n",
    "        print(f\"Number of sequences aligned: {num_sequences_aligned}\")\n",
    "\n",
    "        all_parsed_dataset_output.extend(a3m_dict_msa_search_parsed)\n",
    "\n",
    "    # Sort all the alignments based off of the alignment score\n",
    "    all_parsed_dataset_output.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Now that the alignments across all datasets are sorted, reformat each entry to name and sequence\n",
    "    sorted_parsed_output_formatted = []\n",
    "    for align_tuple in all_parsed_dataset_output:\n",
    "        sorted_parsed_output_formatted.append(align_tuple[0])\n",
    "        sorted_parsed_output_formatted.append(align_tuple[1])\n",
    "\n",
    "    merged_alignments_protein = [f\">query_sequence\\n{sequence}\"]\n",
    "    merged_alignments_protein.extend(sorted_parsed_output_formatted)\n",
    "\n",
    "    print(f\"Total merged alignments: {len(merged_alignments_protein)}\")\n",
    "\n",
    "    # Write merged_alignments_protein to a3M format\n",
    "    a3m_file_path = write_alignments_to_a3m(\n",
    "        merged_alignments_protein, \n",
    "        output_file, \n",
    "        description=f\"Merged protein alignments from MSA-Search NIM ({', '.join(databases)})\"\n",
    "    )\n",
    "    \n",
    "    return merged_alignments_protein, a3m_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b4ad8",
   "metadata": {},
   "source": [
    "## 1.3 Apply Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb36f741",
   "metadata": {},
   "source": [
    "#### Include Databases Queried in MSA-Search NIM and the Amino Acid Query Sequence \n",
    "\n",
    "**NOTE:** No spaces nor carriage returns permitted in AA sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97330f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with KOR (P41145 | OPRK_HUMAN)\n",
    "sequence = 'AIPVIITAVYSVVFVVGLVGNSLVMFVIIRYTKMKTATNIYIFNLALADALVTTTMPFQSTVYLMNSWPFGDVLCKIVISIDYYNMFTSIFTLTMMSVDRYIAVCHPVKALDFRTPLKAKIINICIWLLSSSVGISAIVLGGTKVREDVDVIECSLQFPDDDYSWWDLFMKICVFIFAFVIPVLIIIVCYTLMILRLKSVRLLSGSREKDRNLRRITRLVLVVVAVFVVCWTPIHIFILVEALGSTSHSTAALSSYYFCIALGYTNSSLNPILYAFLDENFKRCF'\n",
    "\n",
    "databases = ['Uniref30_2302', 'colabfold_envdb_202108', 'PDB70_220313']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513cd4d",
   "metadata": {},
   "source": [
    "### Load the MSA `JSON` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6031ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MSA data from: kor_msa.json\n",
      "File size: 429,709 bytes\n",
      "Successfully loaded kor_msa.json\n",
      "Found 3 alignment(s)\n",
      "MSA data loaded successfully!\n",
      "Available keys: ['alignments', 'templates', 'metrics']\n",
      "Alignment databases: ['Uniref30_2302', 'PDB70_220313', 'colabfold_envdb_202108']\n",
      "- Uniref30_2302: ['fasta', 'a3m']\n",
      "- PDB70_220313: ['fasta', 'a3m']\n",
      "- colabfold_envdb_202108: ['fasta', 'a3m']\n"
     ]
    }
   ],
   "source": [
    "# Load MSA data from the JSON file\n",
    "# Example with KOR (P41145 | OPRK_HUMAN)\n",
    "msa_file_path = \"kor_msa.json\"\n",
    "\n",
    "msa_response_dict = load_msa_data(msa_file_path)\n",
    "\n",
    "# Display results\n",
    "if \"error\" in msa_response_dict and msa_response_dict[\"error\"] != \"json_decode_error\":\n",
    "    print(f\"MSA data loading had issues: {msa_response_dict['error']}\")\n",
    "else:\n",
    "    print(f\"MSA data loaded successfully!\")\n",
    "    print(f\"Available keys: {list(msa_response_dict.keys())}\")\n",
    "    if \"alignments\" in msa_response_dict:\n",
    "        alignments = msa_response_dict[\"alignments\"]\n",
    "        print(f\"Alignment databases: {list(alignments.keys())}\")\n",
    "        for db_name, db_data in alignments.items():\n",
    "            if isinstance(db_data, dict):\n",
    "                print(f\"- {db_name}: {list(db_data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0aa1fd",
   "metadata": {},
   "source": [
    "### Parse the MSA alignment results to merge results from all datasets used for MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9da7b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing results from database: Uniref30_2302\n",
      "Number of sequences aligned: 199\n",
      "Parsing results from database: colabfold_envdb_202108\n",
      "Number of sequences aligned: 199\n",
      "Parsing results from database: PDB70_220313\n",
      "Number of sequences aligned: 197\n",
      "Total merged alignments: 1191\n",
      "Writing 596 sequences to a3M format: merged_alignments_protein.a3m\n",
      "Successfully created a3M file:\n",
      "File: merged_alignments_protein.a3m\n",
      "Size: 180,883 bytes\n",
      "Sequences: 596\n"
     ]
    }
   ],
   "source": [
    "merged_alignments_protein, a3m_file_path = process_msa_alignments(\n",
    "    msa_response_dict,\n",
    "    databases,\n",
    "    sequence,\n",
    "    max_sequences_per_db=10000,\n",
    "    output_file=\"merged_alignments_protein.a3m\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9ec22",
   "metadata": {},
   "source": [
    "### Create Filtered Versions of the Full MSA (i.e., Top-100, Subset, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9300623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 596 sequences from input data\n",
      "After filtering: 100 sequences\n",
      "Max sequences limit: 100\n",
      "Min length filter: 50\n",
      "Successfully created filtered a3M file:\n",
      "File: merged_alignments_protein_top100.a3m\n",
      "Size: 30,652 bytes\n",
      "Sequences: 100\n",
      "Parsed 596 sequences from input data\n",
      "After filtering: 10 sequences\n",
      "Max sequences limit: 10\n",
      "Successfully created filtered a3M file:\n",
      "File: merged_alignments_protein_sample.a3m\n",
      "Size: 3,015 bytes\n",
      "Sequences: 10\n"
     ]
    }
   ],
   "source": [
    "# Create a filtered version with top 100 sequences\n",
    "filtered_a3m_path = write_filtered_a3m(\n",
    "    merged_alignments_protein,\n",
    "    \"merged_alignments_protein_top100.a3m\", \n",
    "    max_sequences=100,\n",
    "    min_length=50,\n",
    "    description=\"Top 100 protein alignments from MSA-Search NIM (min length 50 aa)\"\n",
    ")\n",
    "\n",
    "# Create a smaller sample for quick testing\n",
    "sample_a3m_path = write_filtered_a3m(\n",
    "    merged_alignments_protein,\n",
    "    \"merged_alignments_protein_sample.a3m\", \n",
    "    max_sequences=10,\n",
    "    description=\"Sample of 10 protein alignments for testing\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c9d48c",
   "metadata": {},
   "source": [
    "### Analyze All Created `A3M` Format Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39464f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "A3M FILE ANALYSIS\n",
      "============================================================\n",
      "Analyzing a3M file: merged_alignments_protein.a3m\n",
      "File Statistics:\n",
      "File size: 180,883 bytes\n",
      "Total lines: 1192\n",
      "Comment lines: 0\n",
      "Sequence headers: 596\n",
      "Sequence lines: 596\n",
      "Sequence Statistics:\n",
      "Number of sequences: 596\n",
      "Average length: 285.0\n",
      "Length range: 285 - 285\n",
      "First sequence example:\n",
      "Header: >query_sequence\n",
      "Length: 285\n",
      "Preview: AIPVIITAVYSVVFVVGLVGNSLVMFVIIRYTKMKTATNIYIFNLALADALVTTTMPFQSTVYLMNSWPFGDVLCKIVIS...\n",
      "----------------------------------------\n",
      "Analyzing a3M file: merged_alignments_protein_top100.a3m\n",
      "File Statistics:\n",
      "File size: 30,652 bytes\n",
      "Total lines: 200\n",
      "Comment lines: 0\n",
      "Sequence headers: 100\n",
      "Sequence lines: 100\n",
      "Sequence Statistics:\n",
      "Number of sequences: 100\n",
      "Average length: 285.0\n",
      "Length range: 285 - 285\n",
      "First sequence example:\n",
      "Header: >query_sequence\n",
      "Length: 285\n",
      "Preview: AIPVIITAVYSVVFVVGLVGNSLVMFVIIRYTKMKTATNIYIFNLALADALVTTTMPFQSTVYLMNSWPFGDVLCKIVIS...\n",
      "----------------------------------------\n",
      "Analyzing a3M file: merged_alignments_protein_sample.a3m\n",
      "File Statistics:\n",
      "File size: 3,015 bytes\n",
      "Total lines: 20\n",
      "Comment lines: 0\n",
      "Sequence headers: 10\n",
      "Sequence lines: 10\n",
      "Sequence Statistics:\n",
      "Number of sequences: 10\n",
      "Average length: 285.0\n",
      "Length range: 285 - 285\n",
      "First sequence example:\n",
      "Header: >query_sequence\n",
      "Length: 285\n",
      "Preview: AIPVIITAVYSVVFVVGLVGNSLVMFVIIRYTKMKTATNIYIFNLALADALVTTTMPFQSTVYLMNSWPFGDVLCKIVIS...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Analyze all created a3M files\n",
    "print(\"=\" * 60)\n",
    "print(\"A3M FILE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "files_to_analyze = [\n",
    "    \"merged_alignments_protein.a3m\",\n",
    "    \"merged_alignments_protein_top100.a3m\", \n",
    "    \"merged_alignments_protein_sample.a3m\"\n",
    "]\n",
    "\n",
    "for file_name in files_to_analyze:\n",
    "    if Path(file_name).exists():\n",
    "        analyze_a3m_file(file_name)\n",
    "        print(\"-\" * 40)\n",
    "    else:\n",
    "        print(f\"File not found: {file_name}\")\n",
    "        print(\"-\" * 40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c4048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
